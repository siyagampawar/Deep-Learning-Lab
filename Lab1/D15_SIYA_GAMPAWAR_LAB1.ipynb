{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Siya Gampawar\n",
    "Roll No. : D3-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical No. 1: Implementation of Single Perceptron and Creation of Logic Gates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 : Single Perceptron Implementation:\n",
    "\n",
    "o Write a Python script to implement a single perceptron.\n",
    "\n",
    "o Include functions for initializing weights and bias, calculating the weighted\n",
    "sum, applying activation function (e.g., step function)\n",
    "\n",
    "o Test the perceptron on a simple binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=[0.1,0.2,0.3]\n",
    "w_weight=[0.1,0.9,0.5]\n",
    "threshold=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step function\n",
    "def step(weighted_sum):\n",
    "    if weighted_sum >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "    weighted_sum=0\n",
    "    for x,w in zip(x_input,w_weight):\n",
    "        weighted_sum +=x*w\n",
    "        print(weighted_sum)\n",
    "    return step(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000000000000002\n",
      "0.19000000000000003\n",
      "0.34\n",
      "output= 1\n"
     ]
    }
   ],
   "source": [
    "output=perceptron()\n",
    "print(\"output=\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 : Creation of Logic Gates:\n",
    "\n",
    "o Use the single perceptron to create logic gates (AND, OR, NOT).\n",
    "\n",
    "o Define the input patterns for each gate and train the perceptron to produce the\n",
    "correct output.\n",
    "\n",
    "o Evaluate the trained perceptron on different inputs to verify its behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "sinput=[]\n",
    "input=[[1,1],[1,0],[0,1],[0,0]]\n",
    "for i in (input):\n",
    "    sum=0\n",
    "    for j in (i):\n",
    "        sum=sum+j\n",
    "    sinput.append(sum)\n",
    "print(sinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=[2,1,1,0]\n",
    "w_weight=[1,1,1,1]\n",
    "bias=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(su):\n",
    "    out=[]\n",
    "    for i in su:\n",
    "        if i >= 3:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "    su=[]\n",
    "    for x,w in zip(x_input,w_weight):\n",
    "        weighted_sum=0\n",
    "        weighted_sum +=x*w\n",
    "        weighted_sum = weighted_sum + bias\n",
    "        su.append(weighted_sum)\n",
    "    return(su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n",
      "[3, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "x=perceptron()\n",
    "y=step(x)\n",
    "print(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AND gate without bias:\n",
      "Input: [0 0], Predicted Output: 0\n",
      "Input: [0 1], Predicted Output: 0\n",
      "Input: [1 0], Predicted Output: 0\n",
      "Input: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def perceptron_and_gate(inputs):\n",
    "    weights = np.array([0.5, 0.5])\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    output = 1 if weighted_sum >= 1 else 0\n",
    "    return output\n",
    "and_gate_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "print(\"Testing AND gate without bias:\")\n",
    "for input_set in and_gate_inputs:\n",
    "    prediction = perceptron_and_gate(input_set)\n",
    "    print(f\"Input: {input_set}, Predicted Output: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(0, 1) = 0\n",
      "AND(1, 1) = 1\n",
      "AND(0, 0) = 0\n",
      "AND(1, 0) = 0\n"
     ]
    }
   ],
   "source": [
    "#OR BY THIS METHOD\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def unitStep(v): \n",
    "\tif v >= 0: \n",
    "\t\treturn 1\n",
    "\telse: \n",
    "\t\treturn 0\n",
    "\n",
    "def perceptronModel(x, w, b): \n",
    "\tv = np.dot(w, x) + b \n",
    "\ty = unitStep(v) \n",
    "\treturn y \n",
    "\n",
    "# AND Logic Function \n",
    "def AND_logicFunction(x): \n",
    "\tweight = np.array([1, 1]) \n",
    "\tbias = -1.5\n",
    "\treturn perceptronModel(x, weight, bias) \n",
    "\n",
    "test1 = np.array([0, 1]) \n",
    "test2 = np.array([1, 1]) \n",
    "test3 = np.array([0, 0]) \n",
    "test4 = np.array([1, 0]) \n",
    "\n",
    "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1))) \n",
    "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2))) \n",
    "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3))) \n",
    "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing OR gate without bias:\n",
      "Input: [0 0], Predicted Output: 0\n",
      "Input: [0 1], Predicted Output: 1\n",
      "Input: [1 0], Predicted Output: 1\n",
      "Input: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_or_gate(inputs):\n",
    "    weights = np.array([0.5, 0.5])\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    output = 1 if weighted_sum >= 0.5 else 0\n",
    "    return output\n",
    "or_gate_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "print(\"Testing OR gate without bias:\")\n",
    "for input_set in or_gate_inputs:\n",
    "    prediction = perceptron_or_gate(input_set)\n",
    "    print(f\"Input: {input_set}, Predicted Output: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR(0, 1) = 1\n",
      "OR(1, 1) = 1\n",
      "OR(0, 0) = 0\n",
      "OR(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "#OR BY THIS METHOD\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def unitStep(v): \n",
    "\tif v >= 0: \n",
    "\t\treturn 1\n",
    "\telse: \n",
    "\t\treturn 0\n",
    "\n",
    "def perceptronModel(x, w, b): \n",
    "\tv = np.dot(w, x) + b \n",
    "\ty = unitStep(v) \n",
    "\treturn y \n",
    "\n",
    "# OR Logic Function \n",
    "def OR_logicFunction(x): \n",
    "\tweight = np.array([1, 1]) \n",
    "\tbias = -0.5\n",
    "\treturn perceptronModel(x, weight, bias) \n",
    "\n",
    "test1 = np.array([0, 1]) \n",
    "test2 = np.array([1, 1]) \n",
    "test3 = np.array([0, 0]) \n",
    "test4 = np.array([1, 0]) \n",
    "\n",
    "print(\"OR({}, {}) = {}\".format(0, 1, OR_logicFunction(test1))) \n",
    "print(\"OR({}, {}) = {}\".format(1, 1, OR_logicFunction(test2))) \n",
    "print(\"OR({}, {}) = {}\".format(0, 0, OR_logicFunction(test3))) \n",
    "print(\"OR({}, {}) = {}\".format(1, 0, OR_logicFunction(test4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR(0, 1) = 1\n",
      "XOR(1, 1) = 0\n",
      "XOR(0, 0) = 0\n",
      "XOR(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unitStep(v):\n",
    "\tif v >= 0:\n",
    "\t\treturn 1\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "def perceptronModel(x, w, b):\n",
    "\tv = np.dot(w, x) + b\n",
    "\ty = unitStep(v)\n",
    "\treturn y\n",
    "\n",
    "def NOT_logicFunction(x):\n",
    "\twNOT = -1\n",
    "\tbNOT = 0.5\n",
    "\treturn perceptronModel(x, wNOT, bNOT)\n",
    "\n",
    "def AND_logicFunction(x):\n",
    "\tw = np.array([1, 1])\n",
    "\tbAND = -1.5\n",
    "\treturn perceptronModel(x, w, bAND)\n",
    "\n",
    "def OR_logicFunction(x):\n",
    "\tw = np.array([1, 1])\n",
    "\tbOR = -0.5\n",
    "\treturn perceptronModel(x, w, bOR)\n",
    "\n",
    "def XOR_logicFunction(x):\n",
    "\ty1 = AND_logicFunction(x)\n",
    "\ty2 = OR_logicFunction(x)\n",
    "\ty3 = NOT_logicFunction(y1)\n",
    "\tfinal_x = np.array([y2, y3])\n",
    "\tfinalOutput = AND_logicFunction(final_x)\n",
    "\treturn finalOutput\n",
    "\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    "\n",
    "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
    "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment:\n",
    "Single perceptron to create logic gates (NOR, NAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOR GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing NOR gate without bias:\n",
      "Input: [0 0], Predicted Output: 1\n",
      "Input: [0 1], Predicted Output: 0\n",
      "Input: [1 0], Predicted Output: 0\n",
      "Input: [1 1], Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_nor_gate(inputs):\n",
    "    weights = np.array([0.5, 0.5])\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    output = 1 if weighted_sum <= 0 else 0\n",
    "    return output\n",
    "nor_gate_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "print(\"Testing NOR gate without bias:\")\n",
    "for input_set in nor_gate_inputs:\n",
    "    prediction = perceptron_nor_gate(input_set)\n",
    "    print(f\"Input: {input_set}, Predicted Output: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAND GATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing NAND gate without bias:\n",
      "Input: [0 0], Predicted Output: 0\n",
      "Input: [0 1], Predicted Output: 0\n",
      "Input: [1 0], Predicted Output: 0\n",
      "Input: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_nand_gate(inputs):\n",
    "    weights = np.array([0.5, 0.5])\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    output = 1 if weighted_sum <1 else 0\n",
    "    return output\n",
    "and_gate_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "print(\"Testing NAND gate without bias:\")\n",
    "for input_set in and_gate_inputs:\n",
    "    prediction = perceptron_and_gate(input_set)\n",
    "    print(f\"Input: {input_set}, Predicted Output: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1B. Implement Perceptron learning algorithm for classification of following points {P0(-1,-1,-1) , P1(-\n",
    "1,-1,1) , P2(-1,1,-1), P3(-1,1,1) ,P4(1,-1,-1) , P5(1,-1,1) , P6(1,1,-1), P7(1,1,1)} in to two classes:\n",
    "C1={P7 (1,1,1)}\n",
    "C2={ P0(-1,-1,-1), P1(-1,-1,1) , P2(-1,1,-1) , P3(-1,1,1) ,P4(1,-1,-1), P5(1,-1,1) , P6(1,1,-1) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [1, 1, 1], Predicted Output: 1\n",
      "Input: [1, -1, 1], Predicted Output: 0\n",
      "Input: [1, 1, -1], Predicted Output: 0\n",
      "Input: [-1, 1, 1], Predicted Output: 0\n",
      "Input: [-1, -1, 1], Predicted Output: 0\n",
      "Input: [-1, -1, -1], Predicted Output: 0\n",
      "Input: [1, -1, -1], Predicted Output: 0\n",
      "Input: [-1, 1, -1], Predicted Output: 0\n",
      "C1:  [[1, 1, 1]]\n",
      "C2:  [[1, -1, 1], [1, 1, -1], [-1, 1, 1], [-1, -1, 1], [-1, -1, -1], [1, -1, -1], [-1, 1, -1]]\n"
     ]
    }
   ],
   "source": [
    "c1 = []\n",
    "c2 = []\n",
    "def perceptron_1a_gate(inputs):\n",
    "    b = 1\n",
    "    weights = np.array([1,1,1])\n",
    "    weighted_sum = np.dot(inputs, weights) + b\n",
    "    output = 1 if (weighted_sum > 3) else 0\n",
    "    if output==1:\n",
    "      c1.append(inputs)\n",
    "    else:\n",
    "      c2.append(inputs)\n",
    "\n",
    "    return output\n",
    "a_gate_inputs = ([[1, 1 , 1], [1 , -1 , 1], [1, 1 , -1], [-1, 1 , 1], [-1,-1,1], [-1,-1,-1],[1,-1,-1],[-1,1,-1]])\n",
    "for input_set in a_gate_inputs:\n",
    "    prediction = perceptron_1a_gate(input_set)\n",
    "    print(f\"Input: {input_set}, Predicted Output: {prediction}\")\n",
    "print(\"C1: \",c1)\n",
    "print(\"C2: \",c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = {\n",
    "    \"P0\" : np.array([-1,-1,-1]),\n",
    "    \"P1\" : np.array([-1,-1,1]),\n",
    "    \"P2\" : np.array([-1,1,-1]),\n",
    "    \"P3\" : np.array([-1,1,1]),\n",
    "    \"P4\" : np.array([1,-1,-1]),\n",
    "    \"P5\" : np.array([-1,1,-1]),\n",
    "    \"P6\" : np.array([1,1,-1]),\n",
    "    \"P7\" : np.array([1,1,1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "c1 = ['P7']\n",
    "c2 = ['P0','P1','P2','P3','P4','P5','P6']\n",
    "weights = np.zeros(len(data_points['P0']))\n",
    "bias = 0\n",
    "print(weights)\n",
    "epochs = 100\n",
    "learning_rate = 1\n",
    "for epoch in range(epochs):\n",
    "  for point in c2:\n",
    "    x = data_points[point]\n",
    "    y = 1 \n",
    "    prediction = np.dot(weights, x) + bias\n",
    "    if prediction <= 0:\n",
    "      weights += learning_rate * x\n",
    "      bias += learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1C.Write a python program to find the number of linearly separable problems out of total binary\n",
    "classification problems on {P0(-1,-1,-1), P1(-1,-1,1) , P2(-1,1,-1) , P3(-1,1,1) ,P4(1,-1,-1), P5(1,-1,1) ,\n",
    "P6(1,1,-1) , P7(1,1,1) }."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [-2.  2.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=1, epochs=100):\n",
    "        self.W = np.zeros(input_size+1)\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "    def activation_fn(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.insert(x, 0, 1)\n",
    "        z = self.W.T.dot(x)\n",
    "        a = self.activation_fn(z)\n",
    "        return a\n",
    "\n",
    "    def fit(self, X, d):\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(d.shape[0]):\n",
    "                y = self.predict(X[i])\n",
    "                e = d[i] - y\n",
    "                self.W = self.W + self.lr * e * np.insert(X[i], 0, 1)\n",
    "\n",
    "def main():\n",
    "    X = np.array([[-1, -1, -1],\n",
    "                  [-1, -1, 1],\n",
    "                  [-1, 1, -1],\n",
    "                  [-1, 1, 1],\n",
    "                  [1, -1, -1],\n",
    "                  [1, -1, 1],\n",
    "                  [1, 1, -1],\n",
    "                  [1, 1, 1]])\n",
    "    d = np.array([0, 0, 0, 0, 1, 1, 1, 1])  # Labels for linear separability\n",
    "\n",
    "    perceptron = Perceptron(input_size=3)\n",
    "    perceptron.fit(X, d)\n",
    "\n",
    "    print(\"Weights:\", perceptron.W)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:Have Successfully Learned the concept of perceptrons and its significance in Deep Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
